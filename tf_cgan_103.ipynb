{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "irish-siemens",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-platform",
   "metadata": {},
   "source": [
    "## Move weight initilization outside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "satisfactory-aquarium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-d26dccba4c99>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/dipang/.tf1/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/dipang/.tf1/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/dipang/.tf1/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/dipang/.tf1/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/dipang/.tf1/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('./MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sorted-listening",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mb is batch_size\n",
    "mb_size = 64\n",
    "Z_dim = 100\n",
    "\n",
    "X_dim = mnist.train.images.shape[1]\n",
    "y_dim = mnist.train.labels.shape[1]\n",
    "\n",
    "# one hidden layer, add another later?\n",
    "h_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "expanded-taxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
    "    return tf.random_normal(shape=size, stddev=xavier_stddev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "conservative-colorado",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Discriminator Net model \"\"\"\n",
    "\n",
    "real_images = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "labels = tf.placeholder(tf.float32, shape=[None, y_dim])\n",
    "\n",
    "# D_W1 = tf.Variable(xavier_init([X_dim + y_dim, h_dim]))\n",
    "# D_b1 = tf.Variable(tf.zeros(shape=[h_dim]))\n",
    "\n",
    "# D_W2 = tf.Variable(xavier_init([h_dim, 1]))\n",
    "# D_b2 = tf.Variable(tf.zeros(shape=[1]))\n",
    "\n",
    "# theta_D = [D_W1, D_W2, D_b1, D_b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ranking-nashville",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    \"disc_H\" : tf.Variable(xavier_init([X_dim + y_dim, h_dim])),\n",
    "    \"disc_final\": tf.Variable(xavier_init([h_dim, 1])),\n",
    "    \"gen_H\": tf.Variable(xavier_init([Z_dim + y_dim, h_dim])),\n",
    "    \"gen_final\": tf.Variable(xavier_init([h_dim, X_dim]))\n",
    "}\n",
    "\n",
    "bias = {\n",
    "    \"disc_H\" : tf.Variable(xavier_init([h_dim])),\n",
    "    \"disc_final\": tf.Variable(xavier_init([1])),\n",
    "    \"gen_H\": tf.Variable(xavier_init([h_dim])),\n",
    "    \"gen_final\": tf.Variable(xavier_init([X_dim]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "contrary-governor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(x, y, reuse=None):\n",
    "\n",
    "    inputs = tf.concat(axis=1, values=[x, y])\n",
    "\n",
    "    # hidden layer\n",
    "    D_h1 = tf.nn.relu(tf.matmul(inputs, weights[\"disc_H\"]) + bias[\"disc_H\"])\n",
    "        \n",
    "    # output layer\n",
    "    D_logit = tf.matmul(D_h1, weights[\"disc_final\"]) + bias[\"disc_final\"]\n",
    "    D_prob = tf.nn.sigmoid(D_logit)\n",
    "\n",
    "    return D_prob, D_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "settled-breach",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Generator Net model \"\"\"\n",
    "Z = tf.placeholder(tf.float32, shape=[None, Z_dim])\n",
    "\n",
    "# G_W1 = tf.Variable(xavier_init([Z_dim + y_dim, h_dim]))\n",
    "# G_b1 = tf.Variable(tf.zeros(shape=[h_dim]))\n",
    "\n",
    "# G_W2 = tf.Variable(xavier_init([h_dim, X_dim]))\n",
    "# G_b2 = tf.Variable(tf.zeros(shape=[X_dim]))\n",
    "\n",
    "# theta_G = [G_W1, G_W2, G_b1, G_b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "designing-ukraine",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z, y, reuse=None):\n",
    "    \n",
    "    inputs = tf.concat(axis=1, values=[z, y])\n",
    "\n",
    "    # hidden layer\n",
    "    G_h1 = tf.nn.relu(tf.matmul(inputs, weights[\"gen_H\"]) + bias[\"gen_H\"])\n",
    "\n",
    "    # output layer\n",
    "    G_log_prob = tf.matmul(G_h1, weights[\"gen_final\"]) + bias[\"gen_final\"]\n",
    "    # images\n",
    "    G_prob = tf.nn.sigmoid(G_log_prob)\n",
    "\n",
    "    return G_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "thermal-transaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_Z(m, n):\n",
    "    return np.random.uniform(-1., 1., size=[m, n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "comparable-finland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(samples):\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    gs = gridspec.GridSpec(4, 4)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(28, 28), cmap='Greys')\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-boring",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "seasonal-paintball",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_sample = generator(Z, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-glass",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "mechanical-watts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn on real images\n",
    "D_real, D_logit_real = discriminator(real_images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "exterior-introduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what does reuse mean?\n",
    "D_fake, D_logit_fake = discriminator(G_sample, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colonial-convertible",
   "metadata": {},
   "source": [
    "## Discriminator Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aware-parliament",
   "metadata": {},
   "source": [
    "### Losses Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "choice-presence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(logits_in, labels_in):\n",
    "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits_in, labels=labels_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "whole-wages",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_real, labels=tf.ones_like(D_logit_real)))\n",
    "# D_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.zeros_like(D_logit_fake)))\n",
    "# D_loss = D_loss_real + D_loss_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "under-minority",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/dipang/.tf1/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# add smoothing factor\n",
    "sm_f = 0.9\n",
    "D_loss_real = tf.reduce_mean(loss_func(logits_in=D_logit_real, labels_in=tf.ones_like(D_logit_real) * sm_f))\n",
    "# D_loss_real = tf.reduce_mean(loss_func(logits_in=D_logit_real, labels_in=tf.ones_like(D_logit_real)))\n",
    "\n",
    "D_loss_fake = tf.reduce_mean(loss_func(logits_in=D_logit_fake, labels_in=tf.zeros_like(D_logit_fake)))\n",
    "\n",
    "D_loss = D_loss_real + D_loss_fake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-mileage",
   "metadata": {},
   "source": [
    "## Generator Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fabulous-memphis",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_loss = tf.reduce_mean(loss_func(logits_in=D_logit_fake, labels_in=tf.ones_like(D_logit_fake)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-adolescent",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "thermal-vietnam",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-chick",
   "metadata": {},
   "source": [
    "### Collect variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "korean-reach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "\n",
    "d_vars = [var for var in tvars if 'dis' in var.name]\n",
    "g_vars = [var for var in tvars if 'gen' in var.name]\n",
    "\n",
    "print([v.name for v in d_vars])\n",
    "print([v.name for v in g_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "buried-baseline",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_vars = [weights[\"gen_H\"], weights[\"gen_final\"], bias[\"gen_H\"], bias[\"gen_final\"]]\n",
    "dis_vars = [weights[\"disc_H\"], weights[\"disc_final\"], bias[\"disc_H\"], bias[\"disc_final\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "talented-affair",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_solver = tf.train.AdamOptimizer().minimize(D_loss, var_list=dis_vars)\n",
    "# D_solver = tf.train.AdamOptimizer().minimize(D_loss, var_list=theta_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "funky-yukon",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list=gen_vars)\n",
    "# G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list=theta_G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-roads",
   "metadata": {},
   "source": [
    "## Traing Session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-paper",
   "metadata": {},
   "source": [
    "### get next batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "backed-beast",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_batch(mb_size):\n",
    "    return mnist.train.next_batch(mb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "going-fault",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "function"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(get_next_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "involved-dollar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists('./samples2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-kruger",
   "metadata": {},
   "source": [
    "## Reshape and Rescale images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "minus-roulette",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.exists('samples2/'):\n",
    "#     os.makedir('sample2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "objective-peoples",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess = tf.Session()\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "earlier-retreat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "n_sample = 16\n",
    "y_sample = np.zeros(shape=[n_sample, y_dim])\n",
    "\n",
    "for i in range(n_sample):\n",
    "    c = i % 10\n",
    "    y_sample[i, c] = 1\n",
    "    \n",
    "print(y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cubic-mining",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10001\n",
    "saver = tf.train.Saver(var_list=gen_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "appointed-importance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0\n",
      "D loss: 1.148\n",
      "G_loss: 2.7\n",
      "\n",
      "Iter: 1000\n",
      "D loss: 0.003962\n",
      "G_loss: 8.854\n",
      "\n",
      "Iter: 2000\n",
      "D loss: 0.03473\n",
      "G_loss: 6.393\n",
      "\n",
      "Iter: 3000\n",
      "D loss: 0.05589\n",
      "G_loss: 4.724\n",
      "\n",
      "Iter: 4000\n",
      "D loss: 0.0781\n",
      "G_loss: 5.605\n",
      "\n",
      "Iter: 5000\n",
      "D loss: 0.1551\n",
      "G_loss: 6.439\n",
      "\n",
      "Iter: 6000\n",
      "D loss: 0.3096\n",
      "G_loss: 4.31\n",
      "\n",
      "Iter: 7000\n",
      "D loss: 0.3217\n",
      "G_loss: 3.955\n",
      "\n",
      "Iter: 8000\n",
      "D loss: 0.588\n",
      "G_loss: 4.052\n",
      "\n",
      "Iter: 9000\n",
      "D loss: 0.5134\n",
      "G_loss: 2.807\n",
      "\n",
      "Iter: 10000\n",
      "D loss: 0.8305\n",
      "G_loss: 2.612\n",
      "\n",
      "Iter: 11000\n",
      "D loss: 0.4966\n",
      "G_loss: 3.292\n",
      "\n",
      "Iter: 12000\n",
      "D loss: 0.3435\n",
      "G_loss: 2.451\n",
      "\n",
      "Iter: 13000\n",
      "D loss: 0.6255\n",
      "G_loss: 2.648\n",
      "\n",
      "Iter: 14000\n",
      "D loss: 0.7937\n",
      "G_loss: 1.711\n",
      "\n",
      "Iter: 15000\n",
      "D loss: 0.7926\n",
      "G_loss: 1.885\n",
      "\n",
      "Iter: 16000\n",
      "D loss: 0.6785\n",
      "G_loss: 2.248\n",
      "\n",
      "Iter: 17000\n",
      "D loss: 0.7108\n",
      "G_loss: 2.082\n",
      "\n",
      "Iter: 18000\n",
      "D loss: 0.6982\n",
      "G_loss: 2.225\n",
      "\n",
      "Iter: 19000\n",
      "D loss: 0.7506\n",
      "G_loss: 1.91\n",
      "\n",
      "Iter: 20000\n",
      "D loss: 0.7086\n",
      "G_loss: 1.979\n",
      "\n",
      "Iter: 21000\n",
      "D loss: 0.7126\n",
      "G_loss: 1.525\n",
      "\n",
      "Iter: 22000\n",
      "D loss: 0.8644\n",
      "G_loss: 1.754\n",
      "\n",
      "Iter: 23000\n",
      "D loss: 0.7446\n",
      "G_loss: 1.872\n",
      "\n",
      "Iter: 24000\n",
      "D loss: 0.6879\n",
      "G_loss: 2.121\n",
      "\n",
      "Iter: 25000\n",
      "D loss: 0.6118\n",
      "G_loss: 1.95\n",
      "\n",
      "Iter: 26000\n",
      "D loss: 0.8917\n",
      "G_loss: 1.832\n",
      "\n",
      "Iter: 27000\n",
      "D loss: 0.7305\n",
      "G_loss: 1.655\n",
      "\n",
      "Iter: 28000\n",
      "D loss: 0.7808\n",
      "G_loss: 1.946\n",
      "\n",
      "Iter: 29000\n",
      "D loss: 0.8056\n",
      "G_loss: 2.073\n",
      "\n",
      "Iter: 30000\n",
      "D loss: 0.8275\n",
      "G_loss: 1.714\n",
      "\n",
      "Iter: 31000\n",
      "D loss: 0.8597\n",
      "G_loss: 2.273\n",
      "\n",
      "Iter: 32000\n",
      "D loss: 0.7052\n",
      "G_loss: 1.913\n",
      "\n",
      "Iter: 33000\n",
      "D loss: 0.8448\n",
      "G_loss: 2.06\n",
      "\n",
      "Iter: 34000\n",
      "D loss: 0.7339\n",
      "G_loss: 2.042\n",
      "\n",
      "Iter: 35000\n",
      "D loss: 0.7379\n",
      "G_loss: 1.98\n",
      "\n",
      "Iter: 36000\n",
      "D loss: 0.823\n",
      "G_loss: 1.946\n",
      "\n",
      "Iter: 37000\n",
      "D loss: 0.7402\n",
      "G_loss: 1.752\n",
      "\n",
      "Iter: 38000\n",
      "D loss: 0.8402\n",
      "G_loss: 2.213\n",
      "\n",
      "Iter: 39000\n",
      "D loss: 0.6516\n",
      "G_loss: 2.282\n",
      "\n",
      "Iter: 40000\n",
      "D loss: 0.7217\n",
      "G_loss: 1.976\n",
      "\n",
      "Iter: 41000\n",
      "D loss: 0.7389\n",
      "G_loss: 1.95\n",
      "\n",
      "Iter: 42000\n",
      "D loss: 0.7025\n",
      "G_loss: 1.713\n",
      "\n",
      "Iter: 43000\n",
      "D loss: 0.7732\n",
      "G_loss: 1.985\n",
      "\n",
      "Iter: 44000\n",
      "D loss: 0.7903\n",
      "G_loss: 1.907\n",
      "\n",
      "Iter: 45000\n",
      "D loss: 0.7876\n",
      "G_loss: 1.692\n",
      "\n",
      "Iter: 46000\n",
      "D loss: 0.6095\n",
      "G_loss: 1.973\n",
      "\n",
      "Iter: 47000\n",
      "D loss: 0.7441\n",
      "G_loss: 2.131\n",
      "\n",
      "Iter: 48000\n",
      "D loss: 0.8544\n",
      "G_loss: 2.032\n",
      "\n",
      "Iter: 49000\n",
      "D loss: 0.7949\n",
      "G_loss: 1.776\n",
      "\n",
      "Iter: 50000\n",
      "D loss: 0.7713\n",
      "G_loss: 1.873\n",
      "\n",
      "Iter: 51000\n",
      "D loss: 0.6527\n",
      "G_loss: 1.928\n",
      "\n",
      "Iter: 52000\n",
      "D loss: 0.7635\n",
      "G_loss: 1.92\n",
      "\n",
      "Iter: 53000\n",
      "D loss: 0.8975\n",
      "G_loss: 1.692\n",
      "\n",
      "Iter: 54000\n",
      "D loss: 0.9239\n",
      "G_loss: 1.831\n",
      "\n",
      "Iter: 55000\n",
      "D loss: 0.9496\n",
      "G_loss: 1.59\n",
      "\n",
      "Iter: 56000\n",
      "D loss: 0.7297\n",
      "G_loss: 2.219\n",
      "\n",
      "Iter: 57000\n",
      "D loss: 0.8594\n",
      "G_loss: 2.041\n",
      "\n",
      "Iter: 58000\n",
      "D loss: 0.7592\n",
      "G_loss: 1.703\n",
      "\n",
      "Iter: 59000\n",
      "D loss: 0.8432\n",
      "G_loss: 1.409\n",
      "\n",
      "Iter: 60000\n",
      "D loss: 0.8542\n",
      "G_loss: 1.911\n",
      "\n",
      "Iter: 61000\n",
      "D loss: 0.8824\n",
      "G_loss: 2.212\n",
      "\n",
      "Iter: 62000\n",
      "D loss: 0.7392\n",
      "G_loss: 1.835\n",
      "\n",
      "Iter: 63000\n",
      "D loss: 0.7152\n",
      "G_loss: 1.827\n",
      "\n",
      "Iter: 64000\n",
      "D loss: 0.6399\n",
      "G_loss: 2.189\n",
      "\n",
      "Iter: 65000\n",
      "D loss: 0.8542\n",
      "G_loss: 1.854\n",
      "\n",
      "Iter: 66000\n",
      "D loss: 0.7768\n",
      "G_loss: 1.721\n",
      "\n",
      "Iter: 67000\n",
      "D loss: 0.9296\n",
      "G_loss: 1.522\n",
      "\n",
      "Iter: 68000\n",
      "D loss: 0.8001\n",
      "G_loss: 1.957\n",
      "\n",
      "Iter: 69000\n",
      "D loss: 0.7546\n",
      "G_loss: 1.609\n",
      "\n",
      "Iter: 70000\n",
      "D loss: 0.7304\n",
      "G_loss: 1.911\n",
      "\n",
      "Iter: 71000\n",
      "D loss: 0.8624\n",
      "G_loss: 1.866\n",
      "\n",
      "Iter: 72000\n",
      "D loss: 0.9992\n",
      "G_loss: 1.761\n",
      "\n",
      "Iter: 73000\n",
      "D loss: 0.762\n",
      "G_loss: 1.429\n",
      "\n",
      "Iter: 74000\n",
      "D loss: 0.5494\n",
      "G_loss: 2.036\n",
      "\n",
      "Iter: 75000\n",
      "D loss: 0.8376\n",
      "G_loss: 2.005\n",
      "\n",
      "Iter: 76000\n",
      "D loss: 0.962\n",
      "G_loss: 1.564\n",
      "\n",
      "Iter: 77000\n",
      "D loss: 0.8421\n",
      "G_loss: 1.706\n",
      "\n",
      "Iter: 78000\n",
      "D loss: 0.931\n",
      "G_loss: 1.922\n",
      "\n",
      "Iter: 79000\n",
      "D loss: 0.7864\n",
      "G_loss: 1.788\n",
      "\n",
      "Iter: 80000\n",
      "D loss: 0.7928\n",
      "G_loss: 2.054\n",
      "\n",
      "Iter: 81000\n",
      "D loss: 0.6784\n",
      "G_loss: 1.865\n",
      "\n",
      "Iter: 82000\n",
      "D loss: 0.6982\n",
      "G_loss: 2.019\n",
      "\n",
      "Iter: 83000\n",
      "D loss: 0.7747\n",
      "G_loss: 1.757\n",
      "\n",
      "Iter: 84000\n",
      "D loss: 1.122\n",
      "G_loss: 1.618\n",
      "\n",
      "Iter: 85000\n",
      "D loss: 0.6451\n",
      "G_loss: 2.065\n",
      "\n",
      "Iter: 86000\n",
      "D loss: 0.8383\n",
      "G_loss: 2.19\n",
      "\n",
      "Iter: 87000\n",
      "D loss: 0.783\n",
      "G_loss: 1.864\n",
      "\n",
      "Iter: 88000\n",
      "D loss: 0.7896\n",
      "G_loss: 1.81\n",
      "\n",
      "Iter: 89000\n",
      "D loss: 0.8442\n",
      "G_loss: 1.539\n",
      "\n",
      "Iter: 90000\n",
      "D loss: 0.7587\n",
      "G_loss: 1.766\n",
      "\n",
      "Iter: 91000\n",
      "D loss: 0.8612\n",
      "G_loss: 1.967\n",
      "\n",
      "Iter: 92000\n",
      "D loss: 0.9288\n",
      "G_loss: 1.7\n",
      "\n",
      "Iter: 93000\n",
      "D loss: 0.7136\n",
      "G_loss: 2.137\n",
      "\n",
      "Iter: 94000\n",
      "D loss: 0.7223\n",
      "G_loss: 1.971\n",
      "\n",
      "Iter: 95000\n",
      "D loss: 0.7616\n",
      "G_loss: 1.746\n",
      "\n",
      "Iter: 96000\n",
      "D loss: 0.6492\n",
      "G_loss: 1.667\n",
      "\n",
      "Iter: 97000\n",
      "D loss: 0.8744\n",
      "G_loss: 1.912\n",
      "\n",
      "Iter: 98000\n",
      "D loss: 0.6713\n",
      "G_loss: 2.018\n",
      "\n",
      "Iter: 99000\n",
      "D loss: 0.792\n",
      "G_loss: 1.647\n",
      "\n",
      "Iter: 100000\n",
      "D loss: 1.028\n",
      "G_loss: 1.622\n",
      "\n",
      "Iter: 101000\n",
      "D loss: 0.828\n",
      "G_loss: 1.462\n",
      "\n",
      "Iter: 102000\n",
      "D loss: 0.8052\n",
      "G_loss: 2.252\n",
      "\n",
      "Iter: 103000\n",
      "D loss: 0.8863\n",
      "G_loss: 2.24\n",
      "\n",
      "Iter: 104000\n",
      "D loss: 0.8764\n",
      "G_loss: 1.661\n",
      "\n",
      "Iter: 105000\n",
      "D loss: 0.8745\n",
      "G_loss: 1.712\n",
      "\n",
      "Iter: 106000\n",
      "D loss: 0.675\n",
      "G_loss: 1.693\n",
      "\n",
      "Iter: 107000\n",
      "D loss: 0.9294\n",
      "G_loss: 1.959\n",
      "\n",
      "Iter: 108000\n",
      "D loss: 0.7113\n",
      "G_loss: 2.196\n",
      "\n",
      "Iter: 109000\n",
      "D loss: 0.8292\n",
      "G_loss: 1.757\n",
      "\n",
      "Iter: 110000\n",
      "D loss: 0.8746\n",
      "G_loss: 1.881\n",
      "\n",
      "Iter: 111000\n",
      "D loss: 0.7405\n",
      "G_loss: 2.051\n",
      "\n",
      "Iter: 112000\n",
      "D loss: 0.8718\n",
      "G_loss: 1.827\n",
      "\n",
      "Iter: 113000\n",
      "D loss: 0.6159\n",
      "G_loss: 2.095\n",
      "\n",
      "Iter: 114000\n",
      "D loss: 0.7244\n",
      "G_loss: 2.007\n",
      "\n",
      "Iter: 115000\n",
      "D loss: 0.8013\n",
      "G_loss: 2.183\n",
      "\n",
      "Iter: 116000\n",
      "D loss: 0.6013\n",
      "G_loss: 1.93\n",
      "\n",
      "Iter: 117000\n",
      "D loss: 0.8152\n",
      "G_loss: 2.027\n",
      "\n",
      "Iter: 118000\n",
      "D loss: 0.7506\n",
      "G_loss: 1.462\n",
      "\n",
      "Iter: 119000\n",
      "D loss: 0.6591\n",
      "G_loss: 1.831\n",
      "\n",
      "Iter: 120000\n",
      "D loss: 0.743\n",
      "G_loss: 2.027\n",
      "\n",
      "Iter: 121000\n",
      "D loss: 0.7883\n",
      "G_loss: 1.887\n",
      "\n",
      "Iter: 122000\n",
      "D loss: 0.8423\n",
      "G_loss: 1.637\n",
      "\n",
      "Iter: 123000\n",
      "D loss: 0.7866\n",
      "G_loss: 2.024\n",
      "\n",
      "Iter: 124000\n",
      "D loss: 0.6649\n",
      "G_loss: 1.83\n",
      "\n",
      "Iter: 125000\n",
      "D loss: 0.8363\n",
      "G_loss: 1.491\n",
      "\n",
      "Iter: 126000\n",
      "D loss: 0.8106\n",
      "G_loss: 1.87\n",
      "\n",
      "Iter: 127000\n",
      "D loss: 0.9243\n",
      "G_loss: 1.803\n",
      "\n",
      "Iter: 128000\n",
      "D loss: 0.6915\n",
      "G_loss: 1.991\n",
      "\n",
      "Iter: 129000\n",
      "D loss: 0.6786\n",
      "G_loss: 1.893\n",
      "\n",
      "Iter: 130000\n",
      "D loss: 0.9011\n",
      "G_loss: 2.014\n",
      "\n",
      "Iter: 131000\n",
      "D loss: 0.8515\n",
      "G_loss: 1.8\n",
      "\n",
      "Iter: 132000\n",
      "D loss: 0.8021\n",
      "G_loss: 1.987\n",
      "\n",
      "Iter: 133000\n",
      "D loss: 0.7329\n",
      "G_loss: 2.186\n",
      "\n",
      "Iter: 134000\n",
      "D loss: 0.7955\n",
      "G_loss: 1.752\n",
      "\n",
      "Iter: 135000\n",
      "D loss: 0.6747\n",
      "G_loss: 2.073\n",
      "\n",
      "Iter: 136000\n",
      "D loss: 0.7171\n",
      "G_loss: 2.137\n",
      "\n",
      "Iter: 137000\n",
      "D loss: 0.6657\n",
      "G_loss: 2.003\n",
      "\n",
      "Iter: 138000\n",
      "D loss: 0.7034\n",
      "G_loss: 2.35\n",
      "\n",
      "Iter: 139000\n",
      "D loss: 0.8864\n",
      "G_loss: 2.13\n",
      "\n",
      "Iter: 140000\n",
      "D loss: 0.7831\n",
      "G_loss: 2.277\n",
      "\n",
      "Iter: 141000\n",
      "D loss: 0.736\n",
      "G_loss: 1.764\n",
      "\n",
      "Iter: 142000\n",
      "D loss: 0.8325\n",
      "G_loss: 1.941\n",
      "\n",
      "Iter: 143000\n",
      "D loss: 0.6637\n",
      "G_loss: 2.111\n",
      "\n",
      "Iter: 144000\n",
      "D loss: 0.7478\n",
      "G_loss: 2.015\n",
      "\n",
      "Iter: 145000\n",
      "D loss: 0.7967\n",
      "G_loss: 2.193\n",
      "\n",
      "Iter: 146000\n",
      "D loss: 0.7296\n",
      "G_loss: 1.825\n",
      "\n",
      "Iter: 147000\n",
      "D loss: 0.7672\n",
      "G_loss: 2.007\n",
      "\n",
      "Iter: 148000\n",
      "D loss: 0.7508\n",
      "G_loss: 2.279\n",
      "\n",
      "Iter: 149000\n",
      "D loss: 0.703\n",
      "G_loss: 2.184\n",
      "\n",
      "Iter: 150000\n",
      "D loss: 0.7986\n",
      "G_loss: 1.975\n",
      "\n",
      "Iter: 151000\n",
      "D loss: 0.7169\n",
      "G_loss: 1.907\n",
      "\n",
      "Iter: 152000\n",
      "D loss: 0.8712\n",
      "G_loss: 2.007\n",
      "\n",
      "Iter: 153000\n",
      "D loss: 0.8084\n",
      "G_loss: 1.678\n",
      "\n",
      "Iter: 154000\n",
      "D loss: 0.5507\n",
      "G_loss: 2.352\n",
      "\n",
      "Iter: 155000\n",
      "D loss: 0.7147\n",
      "G_loss: 1.672\n",
      "\n",
      "Iter: 156000\n",
      "D loss: 0.6391\n",
      "G_loss: 1.825\n",
      "\n",
      "Iter: 157000\n",
      "D loss: 0.6402\n",
      "G_loss: 2.258\n",
      "\n",
      "Iter: 158000\n",
      "D loss: 0.7457\n",
      "G_loss: 1.953\n",
      "\n",
      "Iter: 159000\n",
      "D loss: 0.809\n",
      "G_loss: 1.734\n",
      "\n",
      "Iter: 160000\n",
      "D loss: 0.7596\n",
      "G_loss: 2.204\n",
      "\n",
      "Iter: 161000\n",
      "D loss: 0.7734\n",
      "G_loss: 1.819\n",
      "\n",
      "Iter: 162000\n",
      "D loss: 0.6603\n",
      "G_loss: 2.156\n",
      "\n",
      "Iter: 163000\n",
      "D loss: 0.8593\n",
      "G_loss: 1.814\n",
      "\n",
      "Iter: 164000\n",
      "D loss: 0.6144\n",
      "G_loss: 2.12\n",
      "\n",
      "Iter: 165000\n",
      "D loss: 0.7851\n",
      "G_loss: 1.824\n",
      "\n",
      "Iter: 166000\n",
      "D loss: 0.8997\n",
      "G_loss: 1.869\n",
      "\n",
      "Iter: 167000\n",
      "D loss: 0.6933\n",
      "G_loss: 2.57\n",
      "\n",
      "Iter: 168000\n",
      "D loss: 0.7043\n",
      "G_loss: 2.262\n",
      "\n",
      "Iter: 169000\n",
      "D loss: 0.6484\n",
      "G_loss: 2.07\n",
      "\n",
      "Iter: 170000\n",
      "D loss: 0.6061\n",
      "G_loss: 2.307\n",
      "\n",
      "Iter: 171000\n",
      "D loss: 0.8213\n",
      "G_loss: 2.062\n",
      "\n",
      "Iter: 172000\n",
      "D loss: 0.6001\n",
      "G_loss: 1.998\n",
      "\n",
      "Iter: 173000\n",
      "D loss: 0.7358\n",
      "G_loss: 2.357\n",
      "\n",
      "Iter: 174000\n",
      "D loss: 0.8483\n",
      "G_loss: 1.611\n",
      "\n",
      "Iter: 175000\n",
      "D loss: 0.5453\n",
      "G_loss: 2.147\n",
      "\n",
      "Iter: 176000\n",
      "D loss: 0.764\n",
      "G_loss: 1.967\n",
      "\n",
      "Iter: 177000\n",
      "D loss: 0.6041\n",
      "G_loss: 2.258\n",
      "\n",
      "Iter: 178000\n",
      "D loss: 0.7461\n",
      "G_loss: 1.598\n",
      "\n",
      "Iter: 179000\n",
      "D loss: 0.6455\n",
      "G_loss: 1.894\n",
      "\n",
      "Iter: 180000\n",
      "D loss: 0.6628\n",
      "G_loss: 2.073\n",
      "\n",
      "Iter: 181000\n",
      "D loss: 0.7985\n",
      "G_loss: 2.178\n",
      "\n",
      "Iter: 182000\n",
      "D loss: 0.6896\n",
      "G_loss: 2.375\n",
      "\n",
      "Iter: 183000\n",
      "D loss: 0.7251\n",
      "G_loss: 2.431\n",
      "\n",
      "Iter: 184000\n",
      "D loss: 0.6511\n",
      "G_loss: 2.315\n",
      "\n",
      "Iter: 185000\n",
      "D loss: 0.7457\n",
      "G_loss: 2.253\n",
      "\n",
      "Iter: 186000\n",
      "D loss: 0.5963\n",
      "G_loss: 2.16\n",
      "\n",
      "Iter: 187000\n",
      "D loss: 0.6406\n",
      "G_loss: 2.205\n",
      "\n",
      "Iter: 188000\n",
      "D loss: 0.6914\n",
      "G_loss: 2.493\n",
      "\n",
      "Iter: 189000\n",
      "D loss: 0.7376\n",
      "G_loss: 2.084\n",
      "\n",
      "Iter: 190000\n",
      "D loss: 0.5456\n",
      "G_loss: 2.503\n",
      "\n",
      "Iter: 191000\n",
      "D loss: 0.7226\n",
      "G_loss: 2.4\n",
      "\n",
      "Iter: 192000\n",
      "D loss: 0.631\n",
      "G_loss: 2.158\n",
      "\n",
      "Iter: 193000\n",
      "D loss: 0.6959\n",
      "G_loss: 2.162\n",
      "\n",
      "Iter: 194000\n",
      "D loss: 0.8683\n",
      "G_loss: 1.879\n",
      "\n",
      "Iter: 195000\n",
      "D loss: 0.6583\n",
      "G_loss: 1.867\n",
      "\n",
      "Iter: 196000\n",
      "D loss: 0.4992\n",
      "G_loss: 2.456\n",
      "\n",
      "Iter: 197000\n",
      "D loss: 0.6706\n",
      "G_loss: 2.727\n",
      "\n",
      "Iter: 198000\n",
      "D loss: 0.6651\n",
      "G_loss: 1.987\n",
      "\n",
      "Iter: 199000\n",
      "D loss: 0.7159\n",
      "G_loss: 1.87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for it in range(200000):\n",
    "        if it % 1000 == 0:\n",
    "            Z_sample = sample_Z(n_sample, Z_dim)\n",
    "            # y_sample = np.zeros(shape=[n_sample, y_dim])\n",
    "            # generate 7 only\n",
    "            # y_sample[:, 7] = 1\n",
    "\n",
    "            samples = sess.run(G_sample, feed_dict={Z: Z_sample, labels:y_sample})\n",
    "\n",
    "            fig = plot(samples)\n",
    "            plt.savefig('samples2/{}.png'.format(str(i).zfill(3)), bbox_inches='tight')\n",
    "            i += 1\n",
    "            plt.close(fig)\n",
    "\n",
    "        X_mb, y_mb = mnist.train.next_batch(mb_size)\n",
    "\n",
    "        Z_sample = sample_Z(mb_size, Z_dim)\n",
    "        _, D_loss_curr = sess.run([D_solver, D_loss], feed_dict={real_images: X_mb, Z: Z_sample, labels:y_mb})\n",
    "        _, G_loss_curr = sess.run([G_solver, G_loss], feed_dict={Z: Z_sample, labels:y_mb})\n",
    "\n",
    "        if it % 1000 == 0:\n",
    "            print('Iter: {}'.format(it))\n",
    "            print('D loss: {:.4}'. format(D_loss_curr))\n",
    "            print('G_loss: {:.4}'.format(G_loss_curr))\n",
    "            print()\n",
    "    saver.save(sess, './models/cgan_model_200000_epoch.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "confidential-gardening",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = np.arange(16)\n",
    "# target[-6:] = target[-6:] - 10\n",
    "# sample_y = np.zeros((16, 10))\n",
    "# for i, num in enumerate(target):\n",
    "#     sample_y[i, num] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bright-arctic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/cgan_model_200000_epoch.ckpt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_new_samples = 16\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    saver.restore(sess,'./models/cgan_model_200000_epoch.ckpt')\n",
    "    \n",
    "    for i in range(10):\n",
    "\n",
    "        sample_z = sample_Z(n_new_samples, Z_dim)\n",
    "\n",
    "        gen_sample = sess.run(generator(Z, labels, reuse=True),feed_dict={Z:sample_z, labels:y_sample})\n",
    "\n",
    "        # new_samples.append(gen_sample)\n",
    "\n",
    "        fig = plot(gen_sample)\n",
    "        img_file = 'samples2/new_' + str(i) +'.png'\n",
    "        plt.savefig(img_file, bbox_inches='tight')\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-reality",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
